{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past decade as the technology had been advanced further, many algorithms that were only available as theories became  able to be implemented using advanced computers. Among them is a neural network that acts and behaves like our brain. It can perceive inputs, compute it in an unseeable manner and output (or send to another cell) a result that we see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These days it is easy to hear or see in news about Artificial Intelligence, Artificial Neural Network(ANN), Convolutional Neural Network(CNN), Recurrent Neural Network(RNN), Generative Adversarial Network(GAN) and so on whose base structure is made up of smaller components of it called 'Perceptron'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What it is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at and compare images of a neuron cell and a perceptron below first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](neuron_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neuron cell consists of three main parts: One for receiving input, one for processing it through the other end and one for transmitting it to another. Same as this, a perceptron has the same structure. One for input, one for processing input to some arbitrary value, and one for output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing part is called 'Activation' that it activates and computes the input in a particular way and transmits to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron can take in two or more inputs and outputs some numerical value and based on this value, weight vectors are adjusted appropriately. Depending on the number of possible distinct output values, it acts as a binary or multi-class classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is how it computes the label of each training point.\n",
    "\\begin{equation}\n",
    "  f(x)=\n",
    "  \\begin{cases}\n",
    "    1, & \\text{if $wx + b > 0$}\n",
    "    \\\\\n",
    "    -1, & \\text{if $wx + b < 0$}\n",
    "  \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When <code>wx + b = 0</code> for a given data point, it means the data point is on the decision boundary (a line separating data) which we will deal with later in the post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process of a perceptron can be shown in three parts.<br>\n",
    "1. Each input values are multiplied with weight vectors\n",
    "2. Those multiplied values are then, summed up together.\n",
    "3. Compute the sign of the final value and return either $1$ or $-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to see that the first and second step is just a dot product between a input vector and a weight vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each weight vector is initialized with 0 values but there have been and are many on-going researches about initializing them with non-zero values to achieve faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, this behaves as a linear classifier and there are two cases when working with a perceptron. One case is when the data points is linearly separable and when it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not deal with the second case because for this case, we have to use gradient descent but using such for a perceptron can be inefficient and since it is just a building block for a much bigger and better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at how to implement a binary perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T02:54:51.203455Z",
     "start_time": "2018-12-20T02:54:48.021527Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:34:59.885018Z",
     "start_time": "2018-12-20T03:34:59.868931Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self, num_class=2, max_iter=1000):\n",
    "        \n",
    "        # Check for appropriate classes and dimension\n",
    "        assert num_class >= 2, \"number of classes should be 2 or more\"\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        self.max_iter = max_iter\n",
    "        self.dim = None\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \n",
    "        self.weights = np.zeros(self.dim)\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        # check label size matches training size\n",
    "        assert len(x) == len(y), \"x and y should have same length\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array(x)\n",
    "            \n",
    "        self.dim = x.shape[1]\n",
    "        self._init_weights()\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            for x1, y1 in zip(x, y):\n",
    "                changed = self._train(x1, y1)\n",
    "\n",
    "            if not changed:\n",
    "                print('Finished training at iteration {}'.format(i+1))\n",
    "                break\n",
    "\n",
    "    def _train(self, x, y):\n",
    "        \n",
    "        # Binary classifier\n",
    "        pred = 1 if np.dot(self.weights, x) >= 0 else -1\n",
    "\n",
    "        if pred != y:\n",
    "            self.weights += x*y\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "            \n",
    "    def predict(self, x):\n",
    "        \n",
    "        assert self.dim != None, \"Must fit the model first\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array([x])\n",
    "\n",
    "        assert x.shape[1] == self.dim, \"Trained Features and Predict Features do not match {} != {}\".format(x.shape[1], self.dim)\n",
    "        \n",
    "        pred = np.array([])\n",
    "\n",
    "        for x1 in x:\n",
    "            res = np.dot(self.weights, x1)\n",
    "            pred = np.append(pred, 1 if res >= 0 else -1)\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see above, I am updating a weight vector even when $wx + b = 0$ which means a data point is on the decision boundary. It is because we don't want to have any data points lying on the boundary to avoid being able to classify it as both $+1$ and $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we declare a perceptron and generate random points for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:35:02.543500Z",
     "start_time": "2018-12-20T03:35:02.539508Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:35:04.028116Z",
     "start_time": "2018-12-20T03:35:04.021122Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = [np.random.normal(1.5, 0.5, 30), np.random.normal(1.5, 0.5, 30)]\n",
    "neg = [np.random.normal(-1.5, 0.5, 30), np.random.normal(-1.5, 0.5, 30)]\n",
    "\n",
    "neg_y = np.array([-1]*30)\n",
    "pos_y = np.ones(30)\n",
    "\n",
    "X = np.append(pos, neg, axis=1).transpose()\n",
    "y = np.append(pos_y, neg_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points will lie on the graph like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![binary perceptron without boundary and bias](binary_noboundary_nobias.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:35:05.475640Z",
     "start_time": "2018-12-20T03:35:05.469633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training at iteration 1\n"
     ]
    }
   ],
   "source": [
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we graph the points with decision boundary, it will look like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![binary without bias and with boudnary](binary_nobias_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when using a perceptron to classify data points, there are infinitely many possible solutions. For example, for the above data points, we could even use horizontal or vertical lines through the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check that the prediction of our data matches true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:35:08.007061Z",
     "start_time": "2018-12-20T03:35:07.998049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(p.predict(X) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's try using other data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:35:10.246971Z",
     "start_time": "2018-12-20T03:35:10.237966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,1], [-3, 2], [5, 5], [-4, -2], [1, -3], [-3, 1]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works great! One problem is that all the decision boundaries go through the origin since with the lack of bias term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To introduce bias, we add the constant 1 in weight vector. So any weight vector will have $[x_1, x_2, 1]$. Every update in iteration, we will either add or substract 1 from the bias term. It's fine to use other value for the bias but depending on it, speed of convergence can differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we modify the class to add the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:38:39.349043Z",
     "start_time": "2018-12-20T03:38:39.331046Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self, num_class=2, max_iter=1000):\n",
    "        \n",
    "        # Check for appropriate classes and dimension\n",
    "        assert num_class >= 2, \"number of classes should be 2 or more\"\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        self.max_iter = max_iter\n",
    "        self.dim = None\n",
    "        \n",
    "    def _init_weights(self):\n",
    "\n",
    "        self.weights = np.zeros(self.dim+1)\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        assert len(x) == len(y), \"x and y should have same length\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array(x)\n",
    "            \n",
    "        self.dim = x.shape[1]\n",
    "        self._init_weights()\n",
    "        \n",
    "        x = np.append(x, np.ones((len(x), 1)), axis=1)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            changed = self._train(x, y)\n",
    "        \n",
    "            if not changed:\n",
    "                print('Finished training at iteration {}'.format(i+1))\n",
    "                return\n",
    "\n",
    "    def _train(self, x, y):\n",
    "\n",
    "        changed = False\n",
    "        prev = self.weights\n",
    "\n",
    "        for x1, y1 in zip(x, y):\n",
    "            pred = 1 if np.dot(self.weights, x1) >= 0 else -1\n",
    "\n",
    "            if pred != y1:\n",
    "                self.weights += x1*y1\n",
    "                changed = True\n",
    "\n",
    "        return changed\n",
    "            \n",
    "    def predict(self, x):\n",
    "        \n",
    "        assert self.dim != None, \"Must fit the model first\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array([x])\n",
    "            \n",
    "        assert x.shape[1] == self.dim, \"Trained Features and Predict Features do not match {} != {}\".format(x.shape[1], self.dim)\n",
    "        \n",
    "        x = np.append(x, np.ones((len(x), 1)), axis=1)\n",
    "        \n",
    "        pred = np.array([])\n",
    "        \n",
    "        for x1 in x:\n",
    "            res = np.dot(self.weights, x1)\n",
    "            pred = np.append(pred, 1 if res >= 0 else -1)\n",
    "                \n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![binary with bias and without boundary](binary_bias_noboundary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:38:41.572220Z",
     "start_time": "2018-12-20T03:38:41.568221Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:38:41.697252Z",
     "start_time": "2018-12-20T03:38:41.687221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training at iteration 2\n"
     ]
    }
   ],
   "source": [
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![binary with bias with boundary](binary_bias_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T20:38:42.635482Z",
     "start_time": "2018-12-17T20:38:42.629481Z"
    }
   },
   "source": [
    "As seen, it works nicely and just to make sure, let's predict the X values and check pred values are same as y labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:38:45.485047Z",
     "start_time": "2018-12-20T03:38:45.477043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = p.predict(X)\n",
    "np.all(pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:38:59.596314Z",
     "start_time": "2018-12-20T03:38:59.588354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I will show how to implement Multi-class Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from the binary classifier is that when binary has only one weight vector (w or w/o bias term), multi-class has one weight vector for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we want to make a model for 3 classes, we would have three different weight vectors corresponding to each of classes. To accommodate it, we only need to change how to initialize and update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:16.787539Z",
     "start_time": "2018-12-20T03:41:16.764499Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self, num_class=2, max_iter=1000):\n",
    "        \n",
    "        # Check for appropriate classes and dimension\n",
    "        assert num_class >= 2, \"number of classes should be 2 or more\"\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        self.max_iter = max_iter\n",
    "        self.dim = None\n",
    "        \n",
    "    def _init_weights(self):\n",
    "\n",
    "        # if classes >= 3, each class has its own weights vector\n",
    "        if self.num_class == 2:\n",
    "            self.weights = np.zeros(self.dim+1)\n",
    "        else:\n",
    "            self.weights = np.zeros((self.num_class, self.dim+1))\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        assert x.shape[0] == len(y), \"x and y should have same length\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        self.dim = x.shape[1]\n",
    "        self._init_weights()\n",
    "        \n",
    "        x = np.append(x, np.ones((len(x), 1)), axis=1)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            changed = self._train(x, y)\n",
    "\n",
    "            if not changed:\n",
    "                print('Finished training at iteration {}'.format(i+1))\n",
    "                return\n",
    "\n",
    "    def _train(self, x, y):\n",
    "        \n",
    "        changed = False\n",
    "        \n",
    "        for x1, y1 in zip(x, y):\n",
    "            \n",
    "            # Binary \n",
    "            if self.num_class == 2:\n",
    "                \n",
    "                pred = 1 if np.dot(self.weights, x1) >= 0 else -1\n",
    "                \n",
    "                if pred != y1:\n",
    "                    self.weights += x1*y1\n",
    "                    changed = True\n",
    "                  \n",
    "            # Multi-class\n",
    "            else:\n",
    "                \n",
    "                pred = np.argmax(np.dot(self.weights, x1))\n",
    "                \n",
    "                if pred != y1:\n",
    "                    self.weights[int(y1)] += x1\n",
    "                    self.weights[pred] -= x1\n",
    "                    \n",
    "                    changed =  True\n",
    "                    \n",
    "        return changed\n",
    "            \n",
    "    def predict(self, x):\n",
    "        \n",
    "        assert self.dim != None, \"Must fit the model first\"\n",
    "        \n",
    "        if type(x) == list:\n",
    "            x = np.array([x])\n",
    "            \n",
    "        assert x.shape[1] == self.dim, \"Trained Features and Predict Features do not match {} != {}\".format(x.shape[1], self.dim)\n",
    "        \n",
    "        x = np.append(x, np.ones((len(x), 1)), axis=1)\n",
    "        \n",
    "        pred = np.array([])\n",
    "        \n",
    "        for x1 in x:\n",
    "            res = np.dot(self.weights, x1)\n",
    "            if self.num_class == 2:\n",
    "                pred = np.append(pred, 1 if res >= 0 else -1)\n",
    "            else:\n",
    "                pred = np.append(pred, np.argmax(res))\n",
    "                \n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:18.334205Z",
     "start_time": "2018-12-20T03:41:18.326216Z"
    }
   },
   "outputs": [],
   "source": [
    "size = 20\n",
    "\n",
    "class1 = [np.random.normal(0, 0.5, size), np.random.normal(8, 0.5, size)]\n",
    "class2 = [np.random.normal(-2, 0.5, size), np.random.normal(4, 0.5, size)]\n",
    "class3 = [np.random.normal(2, 0.5, size), np.random.normal(4, 0.5, size)]\n",
    "\n",
    "y1 = np.zeros((size, 1))\n",
    "y2 = np.ones((size, 1))\n",
    "y3 = np.ones((size, 1)) * 2\n",
    "\n",
    "X = np.append(class1, np.append(class2, class3, axis=1), axis=1).transpose()\n",
    "y = np.append(y1, np.append(y2, y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated data looks like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3 class classifier without boundary](3class_noboundary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:21.801422Z",
     "start_time": "2018-12-20T03:41:21.796425Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Perceptron(num_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:22.673247Z",
     "start_time": "2018-12-20T03:41:22.656258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training at iteration 22\n"
     ]
    }
   ],
   "source": [
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we draw a graph with distinct decision boundaries, it will be something like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3 class classifier with boundary](3class_boundary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:25.917562Z",
     "start_time": "2018-12-20T03:41:25.908563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(p.predict(X) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the model with three points (picked by hands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T03:41:26.825381Z",
     "start_time": "2018-12-20T03:41:26.813389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[-3, 3], [5, 2], [0, 10]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that I have not generated random points is to make it easy to see and check the true label and predicted outcome. But it is fine to pick random points and test it as well and feel free to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Note "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is longer than others but it's not harder. Though a perceptron can work as a classifier, it's hard to see anyone actually using it for the purpose as it is merely a building block for a bigger model: Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In later posts, I will talk more about this neural network with simple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you again all for reading and if there is any type of errors or typing errors, do let me know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
