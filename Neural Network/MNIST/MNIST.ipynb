{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST](mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a data set of hand-written digits from 0 to 9 and used as a guide or a tutorial for Convolutional Neural Network (CNN) as the size of it is not big that it's easy to train and test a model. In this post we will implement two different models using CNN and Fully Connected Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally it is better to use CNN instead of FCL for a better performance and memory allocation but I will use these two to show how each of them works and compare their performance at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this post is to introduce you how to use simple tensorflow functions and build models with it. In-depth explanation about CNN will be covered in later posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, you can download the data from [here](https://www.kaggle.com/c/digit-recognizer/data). I am only using the train.csv file as there is no way for us to evaluate using test.csv. But if you have an account (or want to try) after this tutorial, you can predict values for test set and submit on Kaggle to see how well your model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:46.648037Z",
     "start_time": "2018-12-27T03:51:43.683931Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:50.901922Z",
     "start_time": "2018-12-27T03:51:46.651925Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you load and check out the first image, you will see that very first column is the label and the rest are pixel columns that range from 0 to 255 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:50.959933Z",
     "start_time": "2018-12-27T03:51:50.904923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, we split the first column from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:51.462923Z",
     "start_time": "2018-12-27T03:51:50.967934Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.asarray(data['label'], dtype=np.int32)\n",
    "x = np.asarray(data.drop('label', axis=1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:51.476937Z",
     "start_time": "2018-12-27T03:51:51.467928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total of 42000 examples and 784 columns in each. 784 are the total number of pixels in each image (28 by 28). Pixels are aligned in one long array (784 length) instead of (28,28) and this is fine for fully connected layers but later when we use CNN, we have to convert it back to its original shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's split them into training and testing sets and implement a model using FCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:52.000924Z",
     "start_time": "2018-12-27T03:51:51.481926Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let me briefly explain the structure of a model. First it will take an input array of size (batch size, 784). Then it will be connected to the first hidden layer (fully-connected) of size (, 500) followed by a relu layer. After that I will add another set of hidden layer and relu with the same size. After that will be connected to another fully connected layer with the size of 10. This 10 units will be probability values of each example being classified as its index label. First index (0) will contain the probability of being digit 0, second index (1) being digit 1 and so on and output the label with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each example will be transformed (1, 784) -> (1, 500) -> (1, 500) -> (1, 10) -> (1, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FCL](fcl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each unit in hidden layer is a perceptron covered in [here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers of hidden layer can be thought as a black box of an algorithm that computes the input values in some ways behind the scene and outputs a predicted value at the end. This layer consists of small units called 'perceptron' and the post about perceptron can be found [here](https://tlr.gitbook.io/data-science/neural-network/perceptron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two layers are called fully-connected because each units are connected to the next layers' units. Though in the picture some arrows are missing in hidden layers, each units are actually fully connected to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu is a function that transforms the input it receives to achieve non-linearity (More will be covered in another post) and is called 'Activation function'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a function that builds the structure of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:52.019943Z",
     "start_time": "2018-12-27T03:51:52.002924Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # mode tells if it is used for training, evaluating or predicting\n",
    "    \n",
    "    # Array of examples of pixels\n",
    "    input_layer = features['x']\n",
    "    \n",
    "    hidden1 = tf.layers.dense(input_layer, units=500, activation=tf.nn.relu)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(hidden1, units=500, activation=tf.nn.relu)\n",
    "    \n",
    "    # layer that holds 10 units for probabilities\n",
    "    logits = tf.layers.dense(inputs=hidden2, units=10)\n",
    "    \n",
    "    pred = {\n",
    "            'digit': tf.argmax(input=logits, axis=1),\n",
    "            'prob': tf.nn.softmax(logits)\n",
    "        }\n",
    "    \n",
    "    # if mode is predict, should return next\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=pred)\n",
    "\n",
    "    # loss value needed to train a model and evaluate\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, )\n",
    "    \n",
    "    # if mode is train\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_optimizer = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_optimizer)\n",
    "\n",
    "    # if neither train or predict\n",
    "    evaluation = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=pred['digit'])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logits is a vector of size 10 that holds the probabilities of ten labels and the maximum among them will be classified as the predicted label of each given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:52.060927Z",
     "start_time": "2018-12-27T03:51:52.023929Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002478A045EF0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "  model_fn=model_fn, model_dir=\"./model/\")\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# mnist_classifier.train(\n",
    "#     input_fn=train_input_fn,\n",
    "#     steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_dir in Estimator is a path to save a model we build. You can put it anywhere you want and I am creating a sub-directory named 'model' to store it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model is declared and the first time it trains, it will create a checkpoint once in a while that we can load it later to avoid training it all over again. Below is our evaluation on the model and its accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:53.756929Z",
     "start_time": "2018-12-27T03:51:52.062926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-27-03:51:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-27-03:51:53\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.98190475, global_step = 5000, loss = 0.17396037\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model/model.ckpt-5000\n",
      "{'accuracy': 0.98190475, 'loss': 0.17396037, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": X_test}, y=y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "fcm_eval = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "print(fcm_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's randomly draw 10 examples from testing data and compare the prediction with true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:53.766930Z",
     "start_time": "2018-12-27T03:51:53.759966Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = np.random.randint(0, high=len(X_test), size=10)\n",
    "\n",
    "X_samples = X_test[samples]\n",
    "y_samples = y_test[samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:54.201922Z",
     "start_time": "2018-12-27T03:51:53.768928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": X_samples}, num_epochs=1, shuffle=False)\n",
    "\n",
    "prediction = list(mnist_classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T04:28:14.102155Z",
     "start_time": "2018-12-27T04:28:14.064152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'digit': 1,\n",
       "  'prob': array([0.0000000e+00, 1.0000000e+00, 9.4095213e-15, 6.0534783e-29,\n",
       "         3.5331415e-31, 1.1711298e-33, 2.0040707e-27, 8.5007272e-23,\n",
       "         2.8463980e-31, 3.7244722e-32], dtype=float32)},\n",
       " {'digit': 0,\n",
       "  'prob': array([1.0000000e+00, 3.8130331e-37, 6.2349730e-36, 0.0000000e+00,\n",
       "         0.0000000e+00, 3.5814864e-26, 8.6111131e-37, 0.0000000e+00,\n",
       "         0.0000000e+00, 2.3840322e-38], dtype=float32)},\n",
       " {'digit': 1,\n",
       "  'prob': array([6.5226101e-30, 1.0000000e+00, 3.0400010e-16, 1.2914735e-21,\n",
       "         3.2304384e-17, 7.0729110e-15, 3.8646916e-32, 1.3322372e-26,\n",
       "         7.0250941e-17, 3.3421232e-18], dtype=float32)},\n",
       " {'digit': 0,\n",
       "  'prob': array([1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.0138492e-30,\n",
       "         0.0000000e+00, 0.0000000e+00, 7.1665795e-16, 1.3138436e-15,\n",
       "         7.9213934e-33, 1.2990128e-37], dtype=float32)},\n",
       " {'digit': 4,\n",
       "  'prob': array([2.8911891e-23, 3.9594085e-15, 1.9615884e-13, 2.2591231e-20,\n",
       "         9.9999976e-01, 8.8821073e-17, 2.1321697e-24, 1.2081528e-11,\n",
       "         1.3982296e-11, 2.7312331e-07], dtype=float32)},\n",
       " {'digit': 0,\n",
       "  'prob': array([1.0000000e+00, 1.4622906e-24, 5.3600551e-11, 2.8611191e-14,\n",
       "         1.1262419e-20, 1.9843341e-08, 1.4896989e-09, 1.7410040e-31,\n",
       "         1.4625584e-09, 1.8254336e-16], dtype=float32)},\n",
       " {'digit': 9,\n",
       "  'prob': array([3.27441773e-22, 9.91370282e-27, 2.43543868e-15, 3.57504418e-14,\n",
       "         2.09054610e-06, 2.92580794e-25, 1.82457674e-20, 1.23018045e-11,\n",
       "         1.89159088e-08, 9.99997854e-01], dtype=float32)},\n",
       " {'digit': 1,\n",
       "  'prob': array([1.8931302e-33, 1.0000000e+00, 4.3494351e-17, 5.9798925e-15,\n",
       "         1.6412016e-14, 5.5567313e-18, 1.1128256e-24, 8.0763518e-10,\n",
       "         2.3412819e-11, 1.1636596e-14], dtype=float32)},\n",
       " {'digit': 9,\n",
       "  'prob': array([2.1326464e-19, 8.1656124e-14, 3.8080655e-19, 6.2019244e-14,\n",
       "         1.1153921e-05, 8.4537146e-13, 3.8319808e-18, 8.0243541e-07,\n",
       "         9.3108823e-18, 9.9998808e-01], dtype=float32)},\n",
       " {'digit': 7,\n",
       "  'prob': array([8.6858084e-21, 5.4370521e-23, 2.5062871e-26, 7.0780052e-17,\n",
       "         3.2723818e-19, 6.3090544e-26, 7.2631474e-33, 1.0000000e+00,\n",
       "         4.9947544e-20, 1.0044747e-12], dtype=float32)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prediction](prediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've made a fully-connected model, let's try making another that uses CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to reshape our data to its original 2 dimensional form (28 by 28). We can easily do this with <code>numpy.reshape()</code>. Right now our data has the shape of (42000, 784) and our new form should be (42000, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:54.226936Z",
     "start_time": "2018-12-27T03:51:54.204939Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    \n",
    "    input_layer = tf.reshape(features['x'], shape=(-1, 28, 28, 1))\n",
    "    \n",
    "    # cnn1 = (-1, 28, 28, 16)\n",
    "    cnn1 = tf.layers.conv2d(input_layer, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "    # pool1 = (-1, 14, 14, 16)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=cnn1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # cnn2 = (-1, 14, 14, 32)\n",
    "    cnn2 = tf.layers.conv2d(pool1, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "    # pool2 = (-1, 7, 7, 32)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=cnn2, pool_size=[2,2], strides=2)\n",
    "    \n",
    "    # Flatten the layer \n",
    "    flat = tf.reshape(pool2, [-1, 7 * 7 * 32])\n",
    "    \n",
    "    dense1 = tf.layers.dense(flat, units=1024)\n",
    "    \n",
    "    logits = tf.layers.dense(dense1, units=10)\n",
    "    \n",
    "    pred = {\n",
    "            'digit': tf.argmax(input=logits, axis=1),\n",
    "            'prob': tf.nn.softmax(logits)\n",
    "        }\n",
    "    \n",
    "    # if mode is predict, should return next\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=pred)\n",
    "\n",
    "    \n",
    "    # loss value needed to train a model and evaluate\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # if mode is train\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_optimizer = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_optimizer)\n",
    "\n",
    "    # if neither train or predict\n",
    "    evaluation = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=pred['digit'])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=evaluation)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features is a dictionary argument that contains our data (<code>features['x']</code>). When -1 is passed into a shape, it sets the first dimension to be as big as the first dimension of the passed data. So if we pass a set of 100 examples, this -1 will indicate 100. We are using -1 because the size of data (batch size) we pass in can be arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1 in the last shape form indicates the number of channel each image has. Our MNIST has one channel but usually a colored image has three channels: Red, Green and Blue and in that case, the shape will be (-1, 28, 28, 3). (More on this in later posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter in conv2d can be thought as some arbitrary function (or a layer) that detects specific structures of an image such as horizontal line, vertical line, diagonal line and so on. (Again, more will be covered later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining a model, there are three modes: Train, Evaluate and Predict and the mode argument holds one of these three values and performs tasks accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN is an algorithm that after it takes in images, it transforms the shape of it and while doing that extracts useful features and based on it classifies them into categories. Next is declaring a model and training and evaluating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:51:54.263928Z",
     "start_time": "2018-12-27T03:51:54.231951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './cnn_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002478A2CD4A8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "cnn = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model, model_dir=\"./cnn_model/\")\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# cnn.train(\n",
    "#     input_fn=train_input_fn,\n",
    "#     steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:52:00.224926Z",
     "start_time": "2018-12-27T03:51:54.267934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-27-03:51:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-27-03:51:59\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9839048, global_step = 5000, loss = 0.054781567\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./cnn_model/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "cnn_eval = cnn.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the accuracy and loss of CNN model and Fully Connected Model, we can see that the loss of CNN is much lower and slightly higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T03:52:00.234927Z",
     "start_time": "2018-12-27T03:52:00.227929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM Performace : {'accuracy': 0.98190475, 'loss': 0.17396037, 'global_step': 5000}\n",
      "CNN Performace : {'accuracy': 0.9839048, 'loss': 0.054781567, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "print(f'FCM Performace : {fcm_eval}')\n",
    "print(f'CNN Performace : {cnn_eval}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Note "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though I have showed using a fully connected model, when working with images it is better to use CNN for better and faster performance and efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post's goal was to introduce you to simple neural network and get familiar with some of tensorflow functions. In the next posts, I will cover more in depth about CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always thank you for reading the post and if you have any suggestions, let me know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
