{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/sin_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, linear regression is building a model that to a line that fits data samples with the least loss values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, a model should figure out a proper relation, if there exists, between independent (x) and dependent values (y). This relation could be proportional or not or no relation at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other machine learning examples, it is impossible to predict something with no errors, so our goal is to build a model that produces the least possible loss values which is done by computing the difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One naive loss function can be $$loss = \\sum_i^N(y - \\hat y_i)$$ where $\\hat y_i$ is the predicted values and $N$ is the number of samples. <br>In this post, we will use Mean Squared Error function $$MSE = \\frac{1}{N}\\lVert \\hat y - y \\rVert_2^2$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T16:41:10.299134Z",
     "start_time": "2018-08-20T16:41:10.293841Z"
    }
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we would like to know the relation between the height and weight of a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already tell that the taller the person is, the heavier the weight gets. Let's find out if this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are going to use is from [Kaggle's weight-height](https://www.kaggle.com/mustafaali96/weight-height) uploaded by Mustafa Ali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:22.274801Z",
     "start_time": "2019-06-03T23:16:22.253935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>73.847017</td>\n",
       "      <td>241.893563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>68.781904</td>\n",
       "      <td>162.310473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender     Height      Weight\n",
       "0   Male  73.847017  241.893563\n",
       "1   Male  68.781904  162.310473"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Gender'] == 'Male'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:22.294826Z",
     "start_time": "2019-06-03T23:16:22.277099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Female</td>\n",
       "      <td>58.910732</td>\n",
       "      <td>102.088326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>Female</td>\n",
       "      <td>65.230013</td>\n",
       "      <td>141.305823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender     Height      Weight\n",
       "5000  Female  58.910732  102.088326\n",
       "5001  Female  65.230013  141.305823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Gender'] == 'Female'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:22.314219Z",
     "start_time": "2019-06-03T23:16:22.297418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10,000 data samples and gener, height and weight features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:22.349840Z",
     "start_time": "2019-06-03T23:16:22.316221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.367560</td>\n",
       "      <td>161.440357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.847528</td>\n",
       "      <td>32.108439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>54.263133</td>\n",
       "      <td>64.700127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.505620</td>\n",
       "      <td>135.818051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.318070</td>\n",
       "      <td>161.212928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.174262</td>\n",
       "      <td>187.169525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.998742</td>\n",
       "      <td>269.989699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Height        Weight\n",
       "count  10000.000000  10000.000000\n",
       "mean      66.367560    161.440357\n",
       "std        3.847528     32.108439\n",
       "min       54.263133     64.700127\n",
       "25%       63.505620    135.818051\n",
       "50%       66.318070    161.212928\n",
       "75%       69.174262    187.169525\n",
       "max       78.998742    269.989699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/male_female_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our assumption is right. The weight increases as the height does. Also by the looks of it, we could just ignore gender and treat the samples as one bigger group since one line could still fit pretty decently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we zoom out and view the height and weight samples (of male and female), it looks like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/height_weight_plot1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So surely, we cannot fit a line that goes through the origin to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in [Gradient Descent](https://tlr.gitbook.io/data-science/machine-learning-basics/gradient-descent) post, we first have to choose which loss function we are going to use and define partial derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reuse the codes from the post and try running gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:24.887885Z",
     "start_time": "2019-06-03T23:16:24.870650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def mse(y, x, w, b):\n",
    "    \n",
    "    return np.mean((y - (x * w + b))**2)\n",
    "\n",
    "# Partial Derivative with respect to w\n",
    "def partial_w(y, x, w, b):\n",
    "    \n",
    "    return -2 * np.mean((y - (x * w + b)) * x)\n",
    "\n",
    "# Partial Derivative with respect to b\n",
    "def partial_b(y, x, w, b):\n",
    "    \n",
    "    return -2 * np.mean(y - (x * w + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:27.492959Z",
     "start_time": "2019-06-03T23:16:24.892131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1631769.5829055535\n",
      "Loss : 1.218227932815399e+185\n",
      "Loss : inf\n",
      "Loss : inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/py/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : nan\n",
      "Loss : nan\n",
      "Loss : nan\n",
      "Loss : nan\n",
      "Loss : nan\n",
      "Loss : nan\n"
     ]
    }
   ],
   "source": [
    "x = data['Height']\n",
    "y = data['Weight']\n",
    "\n",
    "w = b = 0\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss = []\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    dw = partial_w(y, x, w, b)\n",
    "    db = partial_b(y, x, w, b)\n",
    "\n",
    "    w = w - dw * learning_rate\n",
    "    b = b - db * learning_rate\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        l = mse(y, x, w, b)\n",
    "        \n",
    "        print('Loss :', l)\n",
    "        \n",
    "        loss.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the loss goes to infinity and becomes nan. Usually this happens when x and y values are not small and the sum of losses gets huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing is normalization while the other is standardization.\n",
    "$$normalization = \\frac{x - min_x}{max_x - min_x}$$\n",
    "$$\\\\$$\n",
    "$$standardization = \\frac{x - \\mu_x}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use both and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:27.512318Z",
     "start_time": "2019-06-03T23:16:27.496813Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, verbose=True, epochs=10000):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    w = b = 0\n",
    "    \n",
    "    iter_ver = epochs*.1\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        dw = partial_w(y, x, w, b)\n",
    "        db = partial_b(y, x, w, b)\n",
    "\n",
    "        w = w - dw * learning_rate\n",
    "        b = b - db * learning_rate\n",
    "\n",
    "        if (i+1) % iter_ver == 0:\n",
    "\n",
    "            loss = mse(y, x, w, b)\n",
    "\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if verbose:\n",
    "                \n",
    "                print(f'Epoch : {i+1} Loss : {loss}')\n",
    "        \n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:56.931587Z",
     "start_time": "2019-06-03T23:16:27.516264Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data['Height']\n",
    "y = data['Weight']\n",
    "\n",
    "norm_x = (x - x.min()) / (x.max() - x.min())\n",
    "norm_y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "std_x = (x - x.mean()) / x.std()\n",
    "std_y = (y - y.mean()) / y.std()\n",
    "\n",
    "norm_w, norm_b, norm_losses = gradient_descent(norm_x, norm_y, verbose=False)\n",
    "std_w, std_b, std_losses = gradient_descent(std_x, std_y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/norm_std_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that standardization converged faster than normalization. As shown, the speed of convergence depends on which scaling method we choose to use. However, it does not mean that we can use anything we want. There are some cases (or models) that prefer normalization over standardization and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example is when we work with SVM model. In this case, standardization will be better to maximize the margin between two classes. More details will be in another post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we standardized samples, we have to do the same when we predict other samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression we used is Ordinary Least Squares but there are other linear regression as well, such as\n",
    "1. Weighted Least Squares\n",
    "2. Generalized Least Squares\n",
    "3. Ridge Regression\n",
    "4. Lasso Regression\n",
    "5. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other forms not mentioned here. The last three regressions are regularized regression which will be covered in a separate post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also it is also possible to have linear regression whose line is actually not a line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say we have the following samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/sin_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the model used above, we will have a line just like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/linear_sin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equation used to generate plots is $$y = x * \\theta_1 + sin(x * \\theta_2)$$ where $\\theta$ is our new weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have two different weights, the derivatives are different as well. The equations are\n",
    "$$$$\n",
    "$$\\frac{\\partial y}{\\partial \\theta_1} = \\frac{-2}{N}(x * (y - \\theta_1 * x - sin(\\theta_2 * x))\\\\$$\n",
    "$$\\frac{\\partial y}{\\partial \\theta_2} = \\frac{-2}{N}(y - (\\theta_1 * x + sin(\\theta_2 * x)) * (x * cos(\\theta_2) * x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:58.403587Z",
     "start_time": "2019-06-03T23:16:58.376886Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(x, theta):\n",
    "    return x*theta[0] + np.sin(x*theta[1])\n",
    "\n",
    "def grad_dt1(x, y, theta):\n",
    "    \n",
    "    return -2 * np.mean(x * (y - theta[0] * x - np.sin(theta[1] * x)) )\n",
    "\n",
    "def grad_dt2(x, y, theta):\n",
    "    \n",
    "    return -2 * np.mean( (y - (theta[0] * x + np.sin(theta[1] * x))) * (x * np.cos(theta[1] * x)) )\n",
    "\n",
    "def nonlinear_gd(x, y, theta, learning_rate=0.01):\n",
    "    \n",
    "    iter_num = 3000\n",
    "    \n",
    "    for i in range(iter_num):\n",
    "        \n",
    "        dt1 = grad_dt1(x, y, theta)\n",
    "        dt2 = grad_dt2(x, y, theta)\n",
    "\n",
    "        dtheta = np.array([dt1, dt2])\n",
    "        theta = theta - learning_rate * dtheta\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T23:16:58.597479Z",
     "start_time": "2019-06-03T23:16:58.411480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99936438, 1.03895846])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.array([0, 0])\n",
    "theta = nonlinear_gd(x, y, theta, learning_rate=0.01)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/nonlinear_sin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it requires us to know which model is used to generate samples, it is possible to fit a line to nonlinear data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post only deals with the basic linear regression without any regularization such as Lasso, Ridge or Elastic Net. There are many versions of it besides Ordinary Least Squares. These topics will be covered in later posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full code [here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you all for reading and if you find any errors or typos or have any suggestions, please let me know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
